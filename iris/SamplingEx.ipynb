{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "x,y = make_classification(n_samples=10000,weights=(0.9,0.1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8952"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.where(y == 0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(np.where(y ==  1)[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partitioning By Class\n",
    "\n",
    "- Good to use when we have a small dataset or when a class is rare.\n",
    "\n",
    "Here is a construction of a 90/5/5 split (training, testing, validation) given we gave a total of 9000 samples of one class and 1,000 samples of another\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,b = make_classification(n_samples=10000, weights=(.9,.1))\n",
    "\n",
    "# Differentiating the sets by creating a dummy datasety and then splitting by classes\n",
    "\n",
    "idx = np.where(b == 0)[0]\n",
    "x0 = a[idx,:]\n",
    "y0 = b[idx]\n",
    "\n",
    "idx = np.where(b == 1)[0]\n",
    "x1 = a[idx,:]\n",
    "y1 = b[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we randomize the order of the samples\n",
    "\n",
    "idx = np.argsort(np.random.random(y0.shape))\n",
    "y0 = y0[idx]\n",
    "x0 = x0[idx]\n",
    "idx = np.argsort(np.random.random(y1.shape))\n",
    "y1 = y1[idx]\n",
    "x1 = x1[idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the first 90 percent of the samples for our two classes and build the training subset with samples in xtrn and labels in ytrn\n",
    "ntrn0 = int(.9*x0.shape[0])\n",
    "ntrn1 = int(.9*x1.shape[0])\n",
    "\n",
    "xtrn = np.zeros((int(ntrn0+ntrn1),20))\n",
    "ytrn = np.zeros(int(ntrn0+ntrn1))\n",
    "\n",
    "xtrn[:ntrn0] = x0[:ntrn0]\n",
    "xtrn[ntrn0:] = x1[:ntrn1]\n",
    "\n",
    "ytrn[:ntrn0] = y0[:ntrn0]\n",
    "ytrn[ntrn0:] = y1[:ntrn1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next we need the split for the validation and testing data set\n",
    "n0 = int(x0.shape[0]-ntrn0)\n",
    "n1 = int(x1.shape[0]-ntrn1)\n",
    "\n",
    "xval = np.zeros((int(n0/2+n1/2),20))\n",
    "yval = np.zeros(int(n0/2+n1/2))\n",
    "\n",
    "xval[:(n0//2)] = x0[ntrn0: (ntrn0+n0//2)]\n",
    "xval[(n0//2):] = x1[ntrn1: (ntrn1+n1//2)]\n",
    "\n",
    "\n",
    "yval[:(n0//2)] = y0[ntrn0: (ntrn0+n0//2)]\n",
    "yval[(n0//2):] = y1[ntrn1: (ntrn1+n1//2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = np.concatenate((x0[(ntrn0+n0//2):],x1[(ntrn1+n1//2):]))\n",
    "ytest = np.concatenate((y0[(ntrn0+n0//2):],y1[(ntrn1+n1//2):]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Sampling\n",
    "\n",
    "- Good to use when we have a small dataset or when a class is rare.\n",
    "\n",
    "Here is a construction of a 90/5/5 split (training, testing, validation) given we gave a total of 9000 samples of one class and 1,000 samples of another\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = make_classification(n_samples=10000, weights=(.9,.1))\n",
    "idx = np.argsort(np.random.random(y.shape[0]))\n",
    "x = x[idx]\n",
    "y = y[idx]\n",
    "\n",
    "ntrn = int(.9*y.shape[0])  \n",
    "nval = int(.05*y.shape[0])\n",
    "\n",
    "xtrn = x[:ntrn]\n",
    "ytrn = y[:ntrn]\n",
    "\n",
    "xval = x[ntrn:(ntrn+nval)]\n",
    "yval = y[ntrn:(ntrn+nval)]\n",
    "\n",
    "xtest = y[(ntrn+nval):]\n",
    "ytest = y[(ntrn+nval):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
